\section{Methodology}
\subsection{Used Technologies}

All code developed during the project was written in the \texttt{python3} programming language, and the Google Colab runtime environment was utilized, as it provides resources that allows rapid testing of DNN (Deep Neural Network) implementations. 
Google Colab also enabled easy sharing of interactive notebooks with the thesis supervisor.

The primary technologies and libraries used in the project include:
\begin{itemize}
    \item \texttt{python3} programming language
    \item \texttt{pytorch} - Chosen as the deep learning framework due to the author's familiarity with it and its widespread adoption among researchers (over 60\% of new paper implementations use \texttt{pytorch} \cite{papersWithCodeTrends}).
    \item \texttt{hdbscan} - Implementation of the HDBSCAN (Hierarchical Density-Based Spatial Clustering of Applications with Noise) algorithm for data clusterization.
    \item \texttt{umap-learn} - Implementation of the UMAP (Uniform Manifold Approximation and Projection) algorithm for dimensionality reduction.
    \item \texttt{som-learn} - Implementation of a SOM (Self Organizing Map) algorithm for data clusterization.
    \item \texttt{scikit-learn}, \texttt{scipy}, \texttt{matplotlib}, \texttt{pandas}, \texttt{numpy} - Common tools used for data analysis in the \texttt{python} ecosystem.
\end{itemize}

\subsection{Key algorithms}
\subsubsection{DNN selection}

The initial choice for classifying XRF spectra involved utilizing a neural network from the ResNet family, specifically ResNet50. The selection of ResNet50 was arbitrary but justified by its reputation as a robust CNN architecture. Notably, ResNet architecture won the ImageNet Large Scale Visual Recognition Challenge in 2015 \cite{ImageNet2015}.

ResNet architecture is characterized by its ability to support very deep networks. This is attributed to the presence of residual connections, which allow each block of network for the learning of residual mappings $g(x) = f(x) - x$ rather than the usual mapping $f(x)$ \cite{d2lResnet}. 

If the desired mapping is identity mapping $f(x) = x$, then block must only learn mapping $g(x) = 0$, which is easy to learn. 
As a result it is hard to degrade performance of this architecture with increasing depth, as it can always learn $g(x) = 0$ - see \prettyref{fig:residual-block}.

\begin{figure}[h] 
  \centering     
  \includesvg[width=0.8\textwidth]{img/residual-block.svg} 
  \caption{``In a regular block (left), the portion within the dotted-line box must directly learn the mapping $f(x)$. 
  In a residual block (right), the portion within the dotted-line box needs to learn the residual mapping $g(x) = f(x) - x$ \cite{d2lResnet}''}
  \label{fig:residual-block}
\end{figure}

However, the original architecture of ResNet incorporates a \emph{Global Average Pooling} operation just before the final fully connected layer. 
This operation calculates the average value over the spatial dimensions of a single feature map. 
In the case of adapting ResNet50 to work with 1D spectra, the input \texttt{torch.Tensor} for global average pooling has a shape of (batch\_size, channels, features) and the output of shape (batch\_size, channels, 1). 
It means that due to averaging over feature dimension the spatial information is lost!

This resulted in the network not performing as expected, especially since peak positions in XRF spectra are crucial to identify elements. 
Furthermore, replacing global average pooling with a flattening operation was not feasible, as it would lead to \\ $\text{{channels}} \times \text{{features}} \times \text{{fully\_connected\_size}}$ total connections with the fully connected layer. 
For example, with an input vector of shape $(\text{{batch\_size}}, 2048, 128)$ (which was observed during development), this would result in approximately $5 \times 10^{8}$ trainable parameters, while default implementation of ResNet50 have only $\sim2.6 \times 10^7$ as a whole!

To address this problem, several possibilities were considered:
\begin{itemize}
    \item Modifying the architecture of ResNet to further reduce dimensionality using convolution and pooling operations.
    \item Reducing size of fully connected layer.
    \item Opting for a completely different architecture.
\end{itemize}

While the choice of model was not crucial for this work, and size of the ResNet fully connected layer could have been easily changed, the decision was made to adopt a more modern approach (for fun and because author forget about second option). 
As a result, the author chose to use the Vision Transformer (ViT).

\subsubsection{ViT}
To understand ViT one ought to first understand how transformers work in general.
Transformer architecture was originally meant to be replacement for RNNs (Recurrent Neural Networks) \cite{Vaswani2017}.
Although transformers need more training data (due to small inductive bias\footnote{e.g. ``In computer vision related tasks, the great success of convolutional neural networks (CNN) is often attributed to its inductive biases, such as locality and translation equivariance. \cite{Mormille2023}''. 
In contrast, transformers exhibit less inductive biases, enabling them explore a broader hypothesis space. 
Consequently, they may converge to local optima and generalize poorly on unseen data, when trained on insufficient data.}) 
than recurrent networks to achieve similar results, they have significant advantage in terms of parallelization.

Unlike classic RNNs, which require the use of the previously calculated hidden state at time step $t-1$ to compute the hidden state at time step $t$, making them non-parallelizable, transformers are highly parallelized, thanks to Multi-Head Attention.
% \sum_{i=1}^{m}\alpha(q, k_i)v_i

Multi-Head Attention works based on \emph{attention mechanism}, which is somehow similar to database query \cite{d2lAttentionMechanism}.
To explain that let's define a key-value database consisting of $(\mathbf{k}, \textbf{v})$ $m$-dimensional vector pairs that can be queried with $\mathbf{q}$ $m$-dimensional vector query: \[ D\overset{\text{def}}{=}\{(\mathbf{k_i}, \mathbf{v_i}) \mid i = 1, 2, \ldots, n\}\]
Then attention over $D$ can be denoted as:
\[ A(\mathbf{q}, D) = \sum_{i=1}^{n}\alpha(\mathbf{q}, \mathbf{k_i})\mathbf{v_i} \]
Where $\alpha(\mathbf{q}, \mathbf{k_i}) \in \mathbb{R}$ are attention weights.

If exactly one of the weights $\alpha(\mathbf{q},\mathbf{k_i}) = 1$, while all others are $0$, then attention works exactly like normal database query returning value of $\mathbf{v_i}$ if there exists $\mathbf{k_i}$ that matches $\mathbf{q}$.

If there are multiple non-zero weights then some linear combination of vectors is retrieved. 
For deep learning applications in most cases we would like to have $\sum_i\alpha(\mathbf{q}, \mathbf{k_i}) = 1$ and $\alpha(\mathbf{q}, \mathbf{k_i}) > 0$. To guarantee this behaviour, the Softmax function can be applied:

\[ \alpha(\mathbf{q}, \mathbf{k_i}) = \frac{\text{exp}(\mathbf{q}, \mathbf{k_i})}{\sum_j \text{exp}(\mathbf{q}, \mathbf{k_j})} \]

The last thing to be defined in this model is how the attention weights are calculated.
In this case there won't be exact matches between $\mathbf{q}$ and $\mathbf{k}$, so $\alpha(\mathbf{q}, \mathbf{k_i}$ fined as must be de




